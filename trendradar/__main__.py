# coding=utf-8
"""
TrendRadar ä¸»ç¨‹åº

çƒ­ç‚¹æ–°é—»èšåˆä¸åˆ†æå·¥å…·
æ”¯æŒ: python -m trendradar
"""

import os
import webbrowser
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import requests

from trendradar.context import AppContext
from trendradar import __version__
from trendradar.core import load_config
from trendradar.core.analyzer import convert_keyword_stats_to_platform_stats
from trendradar.crawler import DataFetcher
from trendradar.storage import convert_crawl_results_to_news_data
from trendradar.utils.time import is_within_days


def check_version_update(
    current_version: str, version_url: str, proxy_url: Optional[str] = None
) -> Tuple[bool, Optional[str]]:
    """æ£€æŸ¥ç‰ˆæœ¬æ›´æ–°"""
    try:
        proxies = None
        if proxy_url:
            proxies = {"http": proxy_url, "https": proxy_url}

        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "text/plain, */*",
            "Cache-Control": "no-cache",
        }

        response = requests.get(
            version_url, proxies=proxies, headers=headers, timeout=10
        )
        response.raise_for_status()

        remote_version = response.text.strip()
        print(f"å½“å‰ç‰ˆæœ¬: {current_version}, è¿œç¨‹ç‰ˆæœ¬: {remote_version}")

        # æ¯”è¾ƒç‰ˆæœ¬
        def parse_version(version_str):
            try:
                parts = version_str.strip().split(".")
                if len(parts) != 3:
                    raise ValueError("ç‰ˆæœ¬å·æ ¼å¼ä¸æ­£ç¡®")
                return int(parts[0]), int(parts[1]), int(parts[2])
            except:
                return 0, 0, 0

        current_tuple = parse_version(current_version)
        remote_tuple = parse_version(remote_version)

        need_update = current_tuple < remote_tuple
        return need_update, remote_version if need_update else None

    except Exception as e:
        print(f"ç‰ˆæœ¬æ£€æŸ¥å¤±è´¥: {e}")
        return False, None


# === ä¸»åˆ†æå™¨ ===
class NewsAnalyzer:
    """æ–°é—»åˆ†æå™¨"""

    # æ¨¡å¼ç­–ç•¥å®šä¹‰
    MODE_STRATEGIES = {
        "incremental": {
            "mode_name": "å¢é‡æ¨¡å¼",
            "description": "å¢é‡æ¨¡å¼ï¼ˆåªå…³æ³¨æ–°å¢æ–°é—»ï¼Œæ— æ–°å¢æ—¶ä¸æ¨é€ï¼‰",
            "realtime_report_type": "å®æ—¶å¢é‡",
            "summary_report_type": "å½“æ—¥æ±‡æ€»",
            "should_send_realtime": True,
            "should_generate_summary": True,
            "summary_mode": "daily",
        },
        "current": {
            "mode_name": "å½“å‰æ¦œå•æ¨¡å¼",
            "description": "å½“å‰æ¦œå•æ¨¡å¼ï¼ˆå½“å‰æ¦œå•åŒ¹é…æ–°é—» + æ–°å¢æ–°é—»åŒºåŸŸ + æŒ‰æ—¶æ¨é€ï¼‰",
            "realtime_report_type": "å®æ—¶å½“å‰æ¦œå•",
            "summary_report_type": "å½“å‰æ¦œå•æ±‡æ€»",
            "should_send_realtime": True,
            "should_generate_summary": True,
            "summary_mode": "current",
        },
        "daily": {
            "mode_name": "å½“æ—¥æ±‡æ€»æ¨¡å¼",
            "description": "å½“æ—¥æ±‡æ€»æ¨¡å¼ï¼ˆæ‰€æœ‰åŒ¹é…æ–°é—» + æ–°å¢æ–°é—»åŒºåŸŸ + æŒ‰æ—¶æ¨é€ï¼‰",
            "realtime_report_type": "",
            "summary_report_type": "å½“æ—¥æ±‡æ€»",
            "should_send_realtime": False,
            "should_generate_summary": True,
            "summary_mode": "daily",
        },
    }

    def __init__(self):
        # åŠ è½½é…ç½®
        print("æ­£åœ¨åŠ è½½é…ç½®...")
        config = load_config()
        print(f"TrendRadar v{__version__} é…ç½®åŠ è½½å®Œæˆ")
        print(f"ç›‘æ§å¹³å°æ•°é‡: {len(config['PLATFORMS'])}")
        print(f"æ—¶åŒº: {config.get('TIMEZONE', 'Asia/Shanghai')}")

        # åˆ›å»ºåº”ç”¨ä¸Šä¸‹æ–‡
        self.ctx = AppContext(config)

        self.request_interval = self.ctx.config["REQUEST_INTERVAL"]
        self.report_mode = self.ctx.config["REPORT_MODE"]
        self.rank_threshold = self.ctx.rank_threshold
        self.is_github_actions = os.environ.get("GITHUB_ACTIONS") == "true"
        self.is_docker_container = self._detect_docker_environment()
        self.update_info = None
        self.proxy_url = None
        self._setup_proxy()
        self.data_fetcher = DataFetcher(self.proxy_url)

        # åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆä½¿ç”¨ AppContextï¼‰
        self._init_storage_manager()

        if self.is_github_actions:
            self._check_version_update()

    def _init_storage_manager(self) -> None:
        """åˆå§‹åŒ–å­˜å‚¨ç®¡ç†å™¨ï¼ˆä½¿ç”¨ AppContextï¼‰"""
        # è·å–æ•°æ®ä¿ç•™å¤©æ•°ï¼ˆæ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–ï¼‰
        env_retention = os.environ.get("STORAGE_RETENTION_DAYS", "").strip()
        if env_retention:
            # ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®
            self.ctx.config["STORAGE"]["RETENTION_DAYS"] = int(env_retention)

        self.storage_manager = self.ctx.get_storage_manager()
        print(f"å­˜å‚¨åç«¯: {self.storage_manager.backend_name}")

        retention_days = self.ctx.config.get("STORAGE", {}).get("RETENTION_DAYS", 0)
        if retention_days > 0:
            print(f"æ•°æ®ä¿ç•™å¤©æ•°: {retention_days} å¤©")

    def _detect_docker_environment(self) -> bool:
        """æ£€æµ‹æ˜¯å¦è¿è¡Œåœ¨ Docker å®¹å™¨ä¸­"""
        try:
            if os.environ.get("DOCKER_CONTAINER") == "true":
                return True

            if os.path.exists("/.dockerenv"):
                return True

            return False
        except Exception:
            return False

    def _should_open_browser(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰“å¼€æµè§ˆå™¨"""
        return not self.is_github_actions and not self.is_docker_container

    def _setup_proxy(self) -> None:
        """è®¾ç½®ä»£ç†é…ç½®"""
        if not self.is_github_actions and self.ctx.config["USE_PROXY"]:
            self.proxy_url = self.ctx.config["DEFAULT_PROXY"]
            print("æœ¬åœ°ç¯å¢ƒï¼Œä½¿ç”¨ä»£ç†")
        elif not self.is_github_actions and not self.ctx.config["USE_PROXY"]:
            print("æœ¬åœ°ç¯å¢ƒï¼Œæœªå¯ç”¨ä»£ç†")
        else:
            print("GitHub Actionsç¯å¢ƒï¼Œä¸ä½¿ç”¨ä»£ç†")

    def _check_version_update(self) -> None:
        """æ£€æŸ¥ç‰ˆæœ¬æ›´æ–°"""
        try:
            need_update, remote_version = check_version_update(
                __version__, self.ctx.config["VERSION_CHECK_URL"], self.proxy_url
            )

            if need_update and remote_version:
                self.update_info = {
                    "current_version": __version__,
                    "remote_version": remote_version,
                }
                print(f"å‘ç°æ–°ç‰ˆæœ¬: {remote_version} (å½“å‰: {__version__})")
            else:
                print("ç‰ˆæœ¬æ£€æŸ¥å®Œæˆï¼Œå½“å‰ä¸ºæœ€æ–°ç‰ˆæœ¬")
        except Exception as e:
            print(f"ç‰ˆæœ¬æ£€æŸ¥å‡ºé”™: {e}")

    def _get_mode_strategy(self) -> Dict:
        """è·å–å½“å‰æ¨¡å¼çš„ç­–ç•¥é…ç½®"""
        return self.MODE_STRATEGIES.get(self.report_mode, self.MODE_STRATEGIES["daily"])

    def _has_notification_configured(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦é…ç½®äº†ä»»ä½•é€šçŸ¥æ¸ é“"""
        cfg = self.ctx.config
        return any(
            [
                cfg["FEISHU_WEBHOOK_URL"],
                cfg["DINGTALK_WEBHOOK_URL"],
                cfg["WEWORK_WEBHOOK_URL"],
                (cfg["TELEGRAM_BOT_TOKEN"] and cfg["TELEGRAM_CHAT_ID"]),
                (
                    cfg["EMAIL_FROM"]
                    and cfg["EMAIL_PASSWORD"]
                    and cfg["EMAIL_TO"]
                ),
                (cfg["NTFY_SERVER_URL"] and cfg["NTFY_TOPIC"]),
                cfg["BARK_URL"],
                cfg["SLACK_WEBHOOK_URL"],
            ]
        )

    def _has_valid_content(
        self, stats: List[Dict], new_titles: Optional[Dict] = None
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ–°é—»å†…å®¹"""
        if self.report_mode == "incremental":
            # å¢é‡æ¨¡å¼ï¼šå¿…é¡»æœ‰æ–°å¢æ ‡é¢˜ä¸”åŒ¹é…äº†å…³é”®è¯æ‰æ¨é€
            has_new_titles = bool(
                new_titles and any(len(titles) > 0 for titles in new_titles.values())
            )
            has_matched_news = any(stat["count"] > 0 for stat in stats)
            return has_new_titles and has_matched_news
        elif self.report_mode == "current":
            # currentæ¨¡å¼ï¼šåªè¦statsæœ‰å†…å®¹å°±è¯´æ˜æœ‰åŒ¹é…çš„æ–°é—»
            return any(stat["count"] > 0 for stat in stats)
        else:
            # å½“æ—¥æ±‡æ€»æ¨¡å¼ä¸‹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŒ¹é…çš„é¢‘ç‡è¯æ–°é—»æˆ–æ–°å¢æ–°é—»
            has_matched_news = any(stat["count"] > 0 for stat in stats)
            has_new_news = bool(
                new_titles and any(len(titles) > 0 for titles in new_titles.values())
            )
            return has_matched_news or has_new_news

    def _generate_ai_summary(
        self,
        rss_items: Optional[List[Dict]] = None,
    ) -> Optional[str]:
        """
        ç”Ÿæˆ AI æ€»ç»“

        æ³¨æ„ï¼šå½“å‰ç‰ˆæœ¬è¿”å›å ä½ç¬¦æç¤º
        å®é™…ä½¿ç”¨æ—¶éœ€è¦é€šè¿‡ MCP å®¢æˆ·ç«¯è°ƒç”¨ get_news_for_summary å·¥å…·è·å–æ•°æ®ï¼Œ
        ç„¶åè®© Claude ä¸ºæ‚¨ç”Ÿæˆä¸ªæ€§åŒ–æ‘˜è¦ã€‚

        Returns:
            AI æ€»ç»“æ–‡æœ¬ï¼Œå¦‚æœæœªå¯ç”¨åˆ™è¿”å› None
        """
        ai_config = self.ctx.config.get("AI", {})
        summary_config = ai_config.get("SUMMARY", {})

        if not summary_config.get("ENABLED", False):
            return None

        # è¿”å›æç¤ºä¿¡æ¯ï¼Œå®é™…æ€»ç»“ç”± MCP å®¢æˆ·ç«¯å®Œæˆ
        # ç”¨æˆ·å¯ä»¥é€šè¿‡ MCP å®¢æˆ·ç«¯ï¼ˆå¦‚ Claude Desktopï¼‰è°ƒç”¨ get_news_for_summary å·¥å…·
        return """
ğŸ’¡ **æç¤º**ï¼šAI æ€»ç»“åŠŸèƒ½å·²å¯ç”¨

è¯·ä½¿ç”¨ MCP å®¢æˆ·ç«¯è°ƒç”¨ `get_news_for_summary` å·¥å…·è·å–åˆ†ç»„æ–°é—»æ•°æ®ï¼Œ
ç„¶åè®© Claude ä¸ºæ‚¨ç”Ÿæˆä¸ªæ€§åŒ–æ‘˜è¦ã€‚

ç¤ºä¾‹è°ƒç”¨æ–¹å¼ï¼š
```
get_news_for_summary({
    "mode": "daily",
    "group_by": "keyword",
    "max_news_per_keyword": 10,
    "include_url": true
})
```
"""

    def _load_analysis_data(
        self,
        quiet: bool = False,
    ) -> Optional[Tuple[Dict, Dict, Dict, Dict, List, List]]:
        """ç»Ÿä¸€çš„æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ï¼Œä½¿ç”¨å½“å‰ç›‘æ§å¹³å°åˆ—è¡¨è¿‡æ»¤å†å²æ•°æ®"""
        try:
            # è·å–å½“å‰é…ç½®çš„ç›‘æ§å¹³å°IDåˆ—è¡¨
            current_platform_ids = self.ctx.platform_ids
            if not quiet:
                print(f"å½“å‰ç›‘æ§å¹³å°: {current_platform_ids}")

            all_results, id_to_name, title_info = self.ctx.read_today_titles(
                current_platform_ids, quiet=quiet
            )

            if not all_results:
                print("æ²¡æœ‰æ‰¾åˆ°å½“å¤©çš„æ•°æ®")
                return None

            total_titles = sum(len(titles) for titles in all_results.values())
            if not quiet:
                print(f"è¯»å–åˆ° {total_titles} ä¸ªæ ‡é¢˜ï¼ˆå·²æŒ‰å½“å‰ç›‘æ§å¹³å°è¿‡æ»¤ï¼‰")

            new_titles = self.ctx.detect_new_titles(current_platform_ids, quiet=quiet)
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()

            return (
                all_results,
                id_to_name,
                title_info,
                new_titles,
                word_groups,
                filter_words,
                global_filters,
            )
        except Exception as e:
            print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return None

    def _prepare_current_title_info(self, results: Dict, time_info: str) -> Dict:
        """ä»å½“å‰æŠ“å–ç»“æœæ„å»ºæ ‡é¢˜ä¿¡æ¯"""
        title_info = {}
        for source_id, titles_data in results.items():
            title_info[source_id] = {}
            for title, title_data in titles_data.items():
                ranks = title_data.get("ranks", [])
                url = title_data.get("url", "")
                mobile_url = title_data.get("mobileUrl", "")

                title_info[source_id][title] = {
                    "first_time": time_info,
                    "last_time": time_info,
                    "count": 1,
                    "ranks": ranks,
                    "url": url,
                    "mobileUrl": mobile_url,
                }
        return title_info

    def _run_analysis_pipeline(
        self,
        data_source: Dict,
        mode: str,
        title_info: Dict,
        new_titles: Dict,
        word_groups: List[Dict],
        filter_words: List[str],
        id_to_name: Dict,
        failed_ids: Optional[List] = None,
        is_daily_summary: bool = False,
        global_filters: Optional[List[str]] = None,
        quiet: bool = False,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
    ) -> Tuple[List[Dict], Optional[str]]:
        """ç»Ÿä¸€çš„åˆ†ææµæ°´çº¿ï¼šæ•°æ®å¤„ç† â†’ ç»Ÿè®¡è®¡ç®— â†’ HTMLç”Ÿæˆ"""

        # ç»Ÿè®¡è®¡ç®—ï¼ˆä½¿ç”¨ AppContextï¼‰
        stats, total_titles = self.ctx.count_frequency(
            data_source,
            word_groups,
            filter_words,
            id_to_name,
            title_info,
            new_titles,
            mode=mode,
            global_filters=global_filters,
            quiet=quiet,
        )

        # å¦‚æœæ˜¯ platform æ¨¡å¼ï¼Œè½¬æ¢æ•°æ®ç»“æ„
        if self.ctx.display_mode == "platform" and stats:
            stats = convert_keyword_stats_to_platform_stats(
                stats,
                self.ctx.weight_config,
                self.ctx.rank_threshold,
            )

        # HTMLç”Ÿæˆï¼ˆå¦‚æœå¯ç”¨ï¼‰
        html_file = None
        if self.ctx.config["STORAGE"]["FORMATS"]["HTML"]:
            html_file = self.ctx.generate_html(
                stats,
                total_titles,
                failed_ids=failed_ids,
                new_titles=new_titles,
                id_to_name=id_to_name,
                mode=mode,
                is_daily_summary=is_daily_summary,
                update_info=self.update_info if self.ctx.config["SHOW_VERSION_UPDATE"] else None,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
            )

        return stats, html_file

    def _send_notification_if_needed(
        self,
        stats: List[Dict],
        report_type: str,
        mode: str,
        failed_ids: Optional[List] = None,
        new_titles: Optional[Dict] = None,
        id_to_name: Optional[Dict] = None,
        html_file_path: Optional[str] = None,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
        ai_summary: Optional[str] = None,
    ) -> bool:
        """ç»Ÿä¸€çš„é€šçŸ¥å‘é€é€»è¾‘ï¼ŒåŒ…å«æ‰€æœ‰åˆ¤æ–­æ¡ä»¶ï¼Œæ”¯æŒçƒ­æ¦œ+RSSåˆå¹¶æ¨é€+AIæ€»ç»“"""
        has_notification = self._has_notification_configured()
        cfg = self.ctx.config

        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆå†…å®¹ï¼ˆçƒ­æ¦œæˆ–RSSï¼‰
        has_news_content = self._has_valid_content(stats, new_titles)
        has_rss_content = bool(rss_items and len(rss_items) > 0)
        has_any_content = has_news_content or has_rss_content

        # è®¡ç®—çƒ­æ¦œåŒ¹é…æ¡æ•°
        news_count = sum(len(stat.get("titles", [])) for stat in stats) if stats else 0
        rss_count = len(rss_items) if rss_items else 0

        if (
            cfg["ENABLE_NOTIFICATION"]
            and has_notification
            and has_any_content
        ):
            # è¾“å‡ºæ¨é€å†…å®¹ç»Ÿè®¡
            content_parts = []
            if news_count > 0:
                content_parts.append(f"çƒ­æ¦œ {news_count} æ¡")
            if rss_count > 0:
                content_parts.append(f"RSS {rss_count} æ¡")
            if ai_summary:
                content_parts.append("AI æ€»ç»“")
            total_count = news_count + rss_count
            print(f"[æ¨é€] å‡†å¤‡å‘é€ï¼š{' + '.join(content_parts)}ï¼Œåˆè®¡ {total_count} æ¡")

            # æ¨é€çª—å£æ§åˆ¶
            if cfg["PUSH_WINDOW"]["ENABLED"]:
                push_manager = self.ctx.create_push_manager()
                time_range_start = cfg["PUSH_WINDOW"]["TIME_RANGE"]["START"]
                time_range_end = cfg["PUSH_WINDOW"]["TIME_RANGE"]["END"]

                if not push_manager.is_in_time_range(time_range_start, time_range_end):
                    now = self.ctx.get_time()
                    print(
                        f"æ¨é€çª—å£æ§åˆ¶ï¼šå½“å‰æ—¶é—´ {now.strftime('%H:%M')} ä¸åœ¨æ¨é€æ—¶é—´çª—å£ {time_range_start}-{time_range_end} å†…ï¼Œè·³è¿‡æ¨é€"
                    )
                    return False

                if cfg["PUSH_WINDOW"]["ONCE_PER_DAY"]:
                    if push_manager.has_pushed_today():
                        print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©å·²æ¨é€è¿‡ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                        return False
                    else:
                        print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©é¦–æ¬¡æ¨é€")

            # å‡†å¤‡æŠ¥å‘Šæ•°æ®
            report_data = self.ctx.prepare_report(stats, failed_ids, new_titles, id_to_name, mode)

            # æ˜¯å¦å‘é€ç‰ˆæœ¬æ›´æ–°ä¿¡æ¯
            update_info_to_send = self.update_info if cfg["SHOW_VERSION_UPDATE"] else None

            # ä½¿ç”¨ NotificationDispatcher å‘é€åˆ°æ‰€æœ‰æ¸ é“ï¼ˆåˆå¹¶çƒ­æ¦œ+RSS+AIæ€»ç»“ï¼‰
            dispatcher = self.ctx.create_notification_dispatcher()
            results = dispatcher.dispatch_all(
                report_data=report_data,
                report_type=report_type,
                update_info=update_info_to_send,
                proxy_url=self.proxy_url,
                mode=mode,
                html_file_path=html_file_path,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
                ai_summary=ai_summary,
            )

            if not results:
                print("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œè·³è¿‡é€šçŸ¥å‘é€")
                return False

            # å¦‚æœæˆåŠŸå‘é€äº†ä»»ä½•é€šçŸ¥ï¼Œä¸”å¯ç”¨äº†æ¯å¤©åªæ¨ä¸€æ¬¡ï¼Œåˆ™è®°å½•æ¨é€
            if (
                cfg["PUSH_WINDOW"]["ENABLED"]
                and cfg["PUSH_WINDOW"]["ONCE_PER_DAY"]
                and any(results.values())
            ):
                push_manager = self.ctx.create_push_manager()
                push_manager.record_push(report_type)

            return True

        elif cfg["ENABLE_NOTIFICATION"] and not has_notification:
            print("[WARNING] Notification enabled but no channels configured")
        elif not cfg["ENABLE_NOTIFICATION"]:
            print(f"è·³è¿‡{report_type}é€šçŸ¥ï¼šé€šçŸ¥åŠŸèƒ½å·²ç¦ç”¨")
        elif (
            cfg["ENABLE_NOTIFICATION"]
            and has_notification
            and not has_any_content
        ):
            mode_strategy = self._get_mode_strategy()
            if "å®æ—¶" in report_type:
                if self.report_mode == "incremental":
                    has_new = bool(
                        new_titles and any(len(titles) > 0 for titles in new_titles.values())
                    )
                    if not has_new and not has_rss_content:
                        print("è·³è¿‡å®æ—¶æ¨é€é€šçŸ¥ï¼šå¢é‡æ¨¡å¼ä¸‹æœªæ£€æµ‹åˆ°æ–°å¢çš„æ–°é—»å’ŒRSS")
                    elif not has_new:
                        print("è·³è¿‡å®æ—¶æ¨é€é€šçŸ¥ï¼šå¢é‡æ¨¡å¼ä¸‹æ–°å¢æ–°é—»æœªåŒ¹é…åˆ°å…³é”®è¯")
                else:
                    print(
                        f"è·³è¿‡å®æ—¶æ¨é€é€šçŸ¥ï¼š{mode_strategy['mode_name']}ä¸‹æœªæ£€æµ‹åˆ°åŒ¹é…çš„æ–°é—»"
                    )
            else:
                print(
                    f"è·³è¿‡{mode_strategy['summary_report_type']}é€šçŸ¥ï¼šæœªåŒ¹é…åˆ°æœ‰æ•ˆçš„æ–°é—»å†…å®¹"
                )

        return False

    def _generate_summary_report(
        self,
        mode_strategy: Dict,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
    ) -> Optional[str]:
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆå¸¦é€šçŸ¥ï¼Œæ”¯æŒRSSåˆå¹¶ï¼‰"""
        summary_type = (
            "å½“å‰æ¦œå•æ±‡æ€»" if mode_strategy["summary_mode"] == "current" else "å½“æ—¥æ±‡æ€»"
        )
        print(f"ç”Ÿæˆ{summary_type}æŠ¥å‘Š...")

        # åŠ è½½åˆ†ææ•°æ®
        analysis_data = self._load_analysis_data()
        if not analysis_data:
            return None

        all_results, id_to_name, title_info, new_titles, word_groups, filter_words, global_filters = (
            analysis_data
        )

        # è¿è¡Œåˆ†ææµæ°´çº¿
        stats, html_file = self._run_analysis_pipeline(
            all_results,
            mode_strategy["summary_mode"],
            title_info,
            new_titles,
            word_groups,
            filter_words,
            id_to_name,
            is_daily_summary=True,
            global_filters=global_filters,
            rss_items=rss_items,
            rss_new_items=rss_new_items,
        )

        if html_file:
            print(f"{summary_type}æŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}")

        # ç”Ÿæˆ AI æ€»ç»“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        ai_summary = self._generate_ai_summary(rss_items=rss_items)

        # å‘é€é€šçŸ¥ï¼ˆåˆå¹¶RSS+AIæ€»ç»“ï¼‰
        self._send_notification_if_needed(
            stats,
            mode_strategy["summary_report_type"],
            mode_strategy["summary_mode"],
            failed_ids=[],
            new_titles=new_titles,
            id_to_name=id_to_name,
            html_file_path=html_file,
            rss_items=rss_items,
            rss_new_items=rss_new_items,
            ai_summary=ai_summary,
        )

        return html_file

    def _generate_summary_html(
        self,
        mode: str = "daily",
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
    ) -> Optional[str]:
        """ç”Ÿæˆæ±‡æ€»HTML"""
        summary_type = "å½“å‰æ¦œå•æ±‡æ€»" if mode == "current" else "å½“æ—¥æ±‡æ€»"
        print(f"ç”Ÿæˆ{summary_type}HTML...")

        # åŠ è½½åˆ†ææ•°æ®ï¼ˆé™é»˜æ¨¡å¼ï¼Œé¿å…é‡å¤è¾“å‡ºæ—¥å¿—ï¼‰
        analysis_data = self._load_analysis_data(quiet=True)
        if not analysis_data:
            return None

        all_results, id_to_name, title_info, new_titles, word_groups, filter_words, global_filters = (
            analysis_data
        )

        # è¿è¡Œåˆ†ææµæ°´çº¿ï¼ˆé™é»˜æ¨¡å¼ï¼Œé¿å…é‡å¤è¾“å‡ºæ—¥å¿—ï¼‰
        _, html_file = self._run_analysis_pipeline(
            all_results,
            mode,
            title_info,
            new_titles,
            word_groups,
            filter_words,
            id_to_name,
            is_daily_summary=True,
            global_filters=global_filters,
            quiet=True,
            rss_items=rss_items,
            rss_new_items=rss_new_items,
        )

        if html_file:
            print(f"{summary_type}HTMLå·²ç”Ÿæˆ: {html_file}")
        return html_file

    def _initialize_and_check_config(self) -> None:
        """é€šç”¨åˆå§‹åŒ–å’Œé…ç½®æ£€æŸ¥"""
        now = self.ctx.get_time()
        print(f"å½“å‰åŒ—äº¬æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}")

        if not self.ctx.config["ENABLE_CRAWLER"]:
            print("çˆ¬è™«åŠŸèƒ½å·²ç¦ç”¨ï¼ˆENABLE_CRAWLER=Falseï¼‰ï¼Œç¨‹åºé€€å‡º")
            return

        has_notification = self._has_notification_configured()
        if not self.ctx.config["ENABLE_NOTIFICATION"]:
            print("é€šçŸ¥åŠŸèƒ½å·²ç¦ç”¨ï¼ˆENABLE_NOTIFICATION=Falseï¼‰ï¼Œå°†åªè¿›è¡Œæ•°æ®æŠ“å–")
        elif not has_notification:
            print("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œå°†åªè¿›è¡Œæ•°æ®æŠ“å–ï¼Œä¸å‘é€é€šçŸ¥")
        else:
            print("é€šçŸ¥åŠŸèƒ½å·²å¯ç”¨ï¼Œå°†å‘é€é€šçŸ¥")

        mode_strategy = self._get_mode_strategy()
        print(f"æŠ¥å‘Šæ¨¡å¼: {self.report_mode}")
        print(f"è¿è¡Œæ¨¡å¼: {mode_strategy['description']}")

    def _crawl_data(self) -> Tuple[Dict, Dict, List]:
        """æ‰§è¡Œæ•°æ®çˆ¬å–"""
        ids = []
        for platform in self.ctx.platforms:
            if "name" in platform:
                ids.append((platform["id"], platform["name"]))
            else:
                ids.append(platform["id"])

        print(
            f"é…ç½®çš„ç›‘æ§å¹³å°: {[p.get('name', p['id']) for p in self.ctx.platforms]}"
        )
        print(f"å¼€å§‹çˆ¬å–æ•°æ®ï¼Œè¯·æ±‚é—´éš” {self.request_interval} æ¯«ç§’")
        Path("output").mkdir(parents=True, exist_ok=True)

        results, id_to_name, failed_ids = self.data_fetcher.crawl_websites(
            ids, self.request_interval
        )

        # è½¬æ¢ä¸º NewsData æ ¼å¼å¹¶ä¿å­˜åˆ°å­˜å‚¨åç«¯
        crawl_time = self.ctx.format_time()
        crawl_date = self.ctx.format_date()
        news_data = convert_crawl_results_to_news_data(
            results, id_to_name, failed_ids, crawl_time, crawl_date
        )

        # ä¿å­˜åˆ°å­˜å‚¨åç«¯ï¼ˆSQLiteï¼‰
        if self.storage_manager.save_news_data(news_data):
            print(f"æ•°æ®å·²ä¿å­˜åˆ°å­˜å‚¨åç«¯: {self.storage_manager.backend_name}")

        # ä¿å­˜ TXT å¿«ç…§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        txt_file = self.storage_manager.save_txt_snapshot(news_data)
        if txt_file:
            print(f"TXT å¿«ç…§å·²ä¿å­˜: {txt_file}")

        # å…¼å®¹ï¼šåŒæ—¶ä¿å­˜åˆ°åŸæœ‰ TXT æ ¼å¼ï¼ˆç¡®ä¿å‘åå…¼å®¹ï¼‰
        if self.ctx.config["STORAGE"]["FORMATS"]["TXT"]:
            title_file = self.ctx.save_titles(results, id_to_name, failed_ids)
            print(f"æ ‡é¢˜å·²ä¿å­˜åˆ°: {title_file}")

        return results, id_to_name, failed_ids

    def _crawl_rss_data(self) -> Tuple[Optional[List[Dict]], Optional[List[Dict]]]:
        """
        æ‰§è¡Œ RSS æ•°æ®æŠ“å–

        Returns:
            (rss_items, rss_new_items) å…ƒç»„ï¼š
            - rss_items: ç»Ÿè®¡æ¡ç›®åˆ—è¡¨ï¼ˆæŒ‰æ¨¡å¼å¤„ç†ï¼Œç”¨äºç»Ÿè®¡åŒºå—ï¼‰
            - rss_new_items: æ–°å¢æ¡ç›®åˆ—è¡¨ï¼ˆç”¨äºæ–°å¢åŒºå—ï¼‰
            å¦‚æœæœªå¯ç”¨æˆ–å¤±è´¥è¿”å› (None, None)
        """
        if not self.ctx.rss_enabled:
            return None, None

        rss_feeds = self.ctx.rss_feeds
        if not rss_feeds:
            print("[RSS] æœªé…ç½®ä»»ä½• RSS æº")
            return None, None

        try:
            from trendradar.crawler.rss import RSSFetcher, RSSFeedConfig

            # æ„å»º RSS æºé…ç½®
            feeds = []
            for feed_config in rss_feeds:
                # è¯»å–å¹¶éªŒè¯å•ä¸ª feed çš„ max_age_daysï¼ˆå¯é€‰ï¼‰
                max_age_days_raw = feed_config.get("max_age_days")
                max_age_days = None
                if max_age_days_raw is not None:
                    try:
                        max_age_days = int(max_age_days_raw)
                        if max_age_days < 0:
                            feed_id = feed_config.get("id", "unknown")
                            print(f"[è­¦å‘Š] RSS feed '{feed_id}' çš„ max_age_days ä¸ºè´Ÿæ•°ï¼Œå°†ä½¿ç”¨å…¨å±€é»˜è®¤å€¼")
                            max_age_days = None
                    except (ValueError, TypeError):
                        feed_id = feed_config.get("id", "unknown")
                        print(f"[è­¦å‘Š] RSS feed '{feed_id}' çš„ max_age_days æ ¼å¼é”™è¯¯ï¼š{max_age_days_raw}")
                        max_age_days = None

                feed = RSSFeedConfig(
                    id=feed_config.get("id", ""),
                    name=feed_config.get("name", ""),
                    url=feed_config.get("url", ""),
                    max_items=feed_config.get("max_items", 50),
                    enabled=feed_config.get("enabled", True),
                    max_age_days=max_age_days,  # None=ä½¿ç”¨å…¨å±€ï¼Œ0=ç¦ç”¨ï¼Œ>0=è¦†ç›–
                )
                if feed.id and feed.url and feed.enabled:
                    feeds.append(feed)

            if not feeds:
                print("[RSS] æ²¡æœ‰å¯ç”¨çš„ RSS æº")
                return None, None

            # åˆ›å»ºæŠ“å–å™¨
            rss_config = self.ctx.rss_config
            # RSS ä»£ç†ï¼šä¼˜å…ˆä½¿ç”¨ RSS ä¸“å±ä»£ç†ï¼Œå¦åˆ™ä½¿ç”¨çˆ¬è™«é»˜è®¤ä»£ç†
            rss_proxy_url = rss_config.get("PROXY_URL", "") or self.proxy_url or ""
            # è·å–é…ç½®çš„æ—¶åŒº
            timezone = self.ctx.config.get("TIMEZONE", "Asia/Shanghai")
            # è·å–æ–°é²œåº¦è¿‡æ»¤é…ç½®
            freshness_config = rss_config.get("FRESHNESS_FILTER", {})
            freshness_enabled = freshness_config.get("ENABLED", True)
            default_max_age_days = freshness_config.get("MAX_AGE_DAYS", 3)

            fetcher = RSSFetcher(
                feeds=feeds,
                request_interval=rss_config.get("REQUEST_INTERVAL", 2000),
                timeout=rss_config.get("TIMEOUT", 15),
                use_proxy=rss_config.get("USE_PROXY", False),
                proxy_url=rss_proxy_url,
                timezone=timezone,
                freshness_enabled=freshness_enabled,
                default_max_age_days=default_max_age_days,
            )

            # æŠ“å–æ•°æ®
            rss_data = fetcher.fetch_all()

            # ä¿å­˜åˆ°å­˜å‚¨åç«¯
            if self.storage_manager.save_rss_data(rss_data):
                print(f"[RSS] æ•°æ®å·²ä¿å­˜åˆ°å­˜å‚¨åç«¯")

                # å¤„ç† RSS æ•°æ®ï¼ˆæŒ‰æ¨¡å¼è¿‡æ»¤ï¼‰å¹¶è¿”å›ç”¨äºåˆå¹¶æ¨é€
                return self._process_rss_data_by_mode(rss_data)
            else:
                print(f"[RSS] æ•°æ®ä¿å­˜å¤±è´¥")
                return None, None

        except ImportError as e:
            print(f"[RSS] ç¼ºå°‘ä¾èµ–: {e}")
            print("[RSS] è¯·å®‰è£… feedparser: pip install feedparser")
            return None, None
        except Exception as e:
            print(f"[RSS] æŠ“å–å¤±è´¥: {e}")
            return None, None

    def _process_rss_data_by_mode(self, rss_data) -> Tuple[Optional[List[Dict]], Optional[List[Dict]]]:
        """
        æŒ‰æŠ¥å‘Šæ¨¡å¼å¤„ç† RSS æ•°æ®ï¼Œè¿”å›ä¸çƒ­æ¦œç›¸åŒæ ¼å¼çš„ç»Ÿè®¡ç»“æ„

        ä¸‰ç§æ¨¡å¼ï¼š
        - daily: å½“æ—¥æ±‡æ€»ï¼Œç»Ÿè®¡=å½“å¤©æ‰€æœ‰æ¡ç›®ï¼Œæ–°å¢=æœ¬æ¬¡æ–°å¢æ¡ç›®
        - current: å½“å‰æ¦œå•ï¼Œç»Ÿè®¡=å½“å‰æ¦œå•æ¡ç›®ï¼Œæ–°å¢=æœ¬æ¬¡æ–°å¢æ¡ç›®
        - incremental: å¢é‡æ¨¡å¼ï¼Œç»Ÿè®¡=æ–°å¢æ¡ç›®ï¼Œæ–°å¢=æ— 

        Args:
            rss_data: å½“å‰æŠ“å–çš„ RSSData å¯¹è±¡

        Returns:
            (rss_stats, rss_new_stats) å…ƒç»„ï¼š
            - rss_stats: RSS å…³é”®è¯ç»Ÿè®¡åˆ—è¡¨ï¼ˆä¸çƒ­æ¦œ stats æ ¼å¼ä¸€è‡´ï¼‰
            - rss_new_stats: RSS æ–°å¢å…³é”®è¯ç»Ÿè®¡åˆ—è¡¨ï¼ˆä¸çƒ­æ¦œ stats æ ¼å¼ä¸€è‡´ï¼‰
        """
        from trendradar.core.analyzer import count_rss_frequency

        rss_config = self.ctx.rss_config

        # æ£€æŸ¥æ˜¯å¦å¯ç”¨ RSS é€šçŸ¥
        if not rss_config.get("NOTIFICATION", {}).get("ENABLED", False):
            return None, None

        # åŠ è½½å…³é”®è¯é…ç½®
        try:
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()
        except FileNotFoundError:
            word_groups, filter_words, global_filters = [], [], []

        timezone = self.ctx.timezone
        max_news_per_keyword = self.ctx.config.get("MAX_NEWS_PER_KEYWORD", 0)
        sort_by_position_first = self.ctx.config.get("SORT_BY_POSITION_FIRST", False)

        rss_stats = None
        rss_new_stats = None

        # 1. é¦–å…ˆè·å–æ–°å¢æ¡ç›®ï¼ˆæ‰€æœ‰æ¨¡å¼éƒ½éœ€è¦ï¼‰
        new_items_dict = self.storage_manager.detect_new_rss_items(rss_data)
        new_items_list = None
        if new_items_dict:
            new_items_list = self._convert_rss_items_to_list(new_items_dict, rss_data.id_to_name)
            if new_items_list:
                print(f"[RSS] æ£€æµ‹åˆ° {len(new_items_list)} æ¡æ–°å¢")

        # 2. æ ¹æ®æ¨¡å¼è·å–ç»Ÿè®¡æ¡ç›®
        if self.report_mode == "incremental":
            # å¢é‡æ¨¡å¼ï¼šç»Ÿè®¡æ¡ç›®å°±æ˜¯æ–°å¢æ¡ç›®
            if not new_items_list:
                print("[RSS] å¢é‡æ¨¡å¼ï¼šæ²¡æœ‰æ–°å¢ RSS æ¡ç›®")
                return None, None

            rss_stats, total = count_rss_frequency(
                rss_items=new_items_list,
                word_groups=word_groups,
                filter_words=filter_words,
                global_filters=global_filters,
                new_items=new_items_list,  # å¢é‡æ¨¡å¼æ‰€æœ‰éƒ½æ˜¯æ–°å¢
                max_news_per_keyword=max_news_per_keyword,
                sort_by_position_first=sort_by_position_first,
                timezone=timezone,
                rank_threshold=self.rank_threshold,
                quiet=False,
            )
            if not rss_stats:
                print("[RSS] å¢é‡æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…åæ²¡æœ‰å†…å®¹")
                return None, None

        elif self.report_mode == "current":
            # å½“å‰æ¦œå•æ¨¡å¼ï¼šç»Ÿè®¡=å½“å‰æ¦œå•æ‰€æœ‰æ¡ç›®
            latest_data = self.storage_manager.get_latest_rss_data(rss_data.date)
            if not latest_data:
                print("[RSS] å½“å‰æ¦œå•æ¨¡å¼ï¼šæ²¡æœ‰ RSS æ•°æ®")
                return None, None

            all_items_list = self._convert_rss_items_to_list(latest_data.items, latest_data.id_to_name)
            rss_stats, total = count_rss_frequency(
                rss_items=all_items_list,
                word_groups=word_groups,
                filter_words=filter_words,
                global_filters=global_filters,
                new_items=new_items_list,  # æ ‡è®°æ–°å¢
                max_news_per_keyword=max_news_per_keyword,
                sort_by_position_first=sort_by_position_first,
                timezone=timezone,
                rank_threshold=self.rank_threshold,
                quiet=False,
            )
            if not rss_stats:
                print("[RSS] å½“å‰æ¦œå•æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…åæ²¡æœ‰å†…å®¹")
                return None, None

            # ç”Ÿæˆæ–°å¢ç»Ÿè®¡
            if new_items_list:
                rss_new_stats, _ = count_rss_frequency(
                    rss_items=new_items_list,
                    word_groups=word_groups,
                    filter_words=filter_words,
                    global_filters=global_filters,
                    new_items=new_items_list,
                    max_news_per_keyword=max_news_per_keyword,
                    sort_by_position_first=sort_by_position_first,
                    timezone=timezone,
                    rank_threshold=self.rank_threshold,
                    quiet=True,
                )

        else:
            # daily æ¨¡å¼ï¼šç»Ÿè®¡=å½“å¤©æ‰€æœ‰æ¡ç›®
            all_data = self.storage_manager.get_rss_data(rss_data.date)
            if not all_data:
                print("[RSS] å½“æ—¥æ±‡æ€»æ¨¡å¼ï¼šæ²¡æœ‰ RSS æ•°æ®")
                return None, None

            all_items_list = self._convert_rss_items_to_list(all_data.items, all_data.id_to_name)
            rss_stats, total = count_rss_frequency(
                rss_items=all_items_list,
                word_groups=word_groups,
                filter_words=filter_words,
                global_filters=global_filters,
                new_items=new_items_list,  # æ ‡è®°æ–°å¢
                max_news_per_keyword=max_news_per_keyword,
                sort_by_position_first=sort_by_position_first,
                timezone=timezone,
                rank_threshold=self.rank_threshold,
                quiet=False,
            )
            if not rss_stats:
                print("[RSS] å½“æ—¥æ±‡æ€»æ¨¡å¼ï¼šå…³é”®è¯åŒ¹é…åæ²¡æœ‰å†…å®¹")
                return None, None

            # ç”Ÿæˆæ–°å¢ç»Ÿè®¡
            if new_items_list:
                rss_new_stats, _ = count_rss_frequency(
                    rss_items=new_items_list,
                    word_groups=word_groups,
                    filter_words=filter_words,
                    global_filters=global_filters,
                    new_items=new_items_list,
                    max_news_per_keyword=max_news_per_keyword,
                    sort_by_position_first=sort_by_position_first,
                    timezone=timezone,
                    rank_threshold=self.rank_threshold,
                    quiet=True,
                )

        return rss_stats, rss_new_stats

    def _convert_rss_items_to_list(self, items_dict: Dict, id_to_name: Dict) -> List[Dict]:
        """å°† RSS æ¡ç›®å­—å…¸è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼ï¼Œå¹¶åº”ç”¨æ–°é²œåº¦è¿‡æ»¤ï¼ˆç”¨äºæ¨é€ï¼‰"""
        rss_items = []
        filtered_count = 0

        # è·å–æ–°é²œåº¦è¿‡æ»¤é…ç½®
        rss_config = self.ctx.rss_config
        freshness_config = rss_config.get("FRESHNESS_FILTER", {})
        freshness_enabled = freshness_config.get("ENABLED", True)
        default_max_age_days = freshness_config.get("MAX_AGE_DAYS", 3)
        timezone = self.ctx.config.get("TIMEZONE", "Asia/Shanghai")

        # æ„å»º feed_id -> max_age_days çš„æ˜ å°„
        feed_max_age_map = {}
        for feed_cfg in self.ctx.rss_feeds:
            feed_id = feed_cfg.get("id", "")
            max_age = feed_cfg.get("max_age_days")
            if max_age is not None:
                try:
                    feed_max_age_map[feed_id] = int(max_age)
                except (ValueError, TypeError):
                    pass

        for feed_id, items in items_dict.items():
            # ç¡®å®šæ­¤ feed çš„ max_age_days
            max_days = feed_max_age_map.get(feed_id)
            if max_days is None:
                max_days = default_max_age_days

            for item in items:
                # åº”ç”¨æ–°é²œåº¦è¿‡æ»¤ï¼ˆä»…åœ¨å¯ç”¨æ—¶ï¼‰
                if freshness_enabled and max_days > 0:
                    if item.published_at and not is_within_days(item.published_at, max_days, timezone):
                        filtered_count += 1
                        continue  # è·³è¿‡è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ç« 

                rss_items.append({
                    "title": item.title,
                    "feed_id": feed_id,
                    "feed_name": id_to_name.get(feed_id, feed_id),
                    "url": item.url,
                    "published_at": item.published_at,
                    "summary": item.summary,
                    "author": item.author,
                })

        # è¾“å‡ºè¿‡æ»¤ç»Ÿè®¡
        if filtered_count > 0:
            print(f"[RSS] æ–°é²œåº¦è¿‡æ»¤ï¼šè·³è¿‡ {filtered_count} ç¯‡è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—§æ–‡ç« ï¼ˆä»ä¿ç•™åœ¨æ•°æ®åº“ä¸­ï¼‰")

        return rss_items

    def _filter_rss_by_keywords(self, rss_items: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨ frequency_words.txt è¿‡æ»¤ RSS æ¡ç›®"""
        try:
            word_groups, filter_words, global_filters = self.ctx.load_frequency_words()
            if word_groups or filter_words or global_filters:
                from trendradar.core.frequency import matches_word_groups
                filtered_items = []
                for item in rss_items:
                    title = item.get("title", "")
                    if matches_word_groups(title, word_groups, filter_words, global_filters):
                        filtered_items.append(item)

                original_count = len(rss_items)
                rss_items = filtered_items
                print(f"[RSS] å…³é”®è¯è¿‡æ»¤åå‰©ä½™ {len(rss_items)}/{original_count} æ¡")

                if not rss_items:
                    print("[RSS] å…³é”®è¯è¿‡æ»¤åæ²¡æœ‰åŒ¹é…å†…å®¹")
                    return []
        except FileNotFoundError:
            # frequency_words.txt ä¸å­˜åœ¨æ—¶è·³è¿‡è¿‡æ»¤
            pass
        return rss_items

    def _process_rss_report_and_notification(self, rss_data) -> None:
        """å¤„ç† RSS æŠ¥å‘Šç”Ÿæˆå’Œé€šçŸ¥å‘é€ï¼ˆç‹¬ç«‹æ¨é€ï¼Œå·²åºŸå¼ƒï¼‰"""
        # æ­¤æ–¹æ³•ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œä½†ä¸å†ä½¿ç”¨
        # RSS ç°åœ¨ä¸çƒ­æ¦œåˆå¹¶æ¨é€
        pass

    def _generate_rss_html_report(self, rss_items: list, feeds_info: dict) -> str:
        """ç”Ÿæˆ RSS HTML æŠ¥å‘Š"""
        try:
            from trendradar.report.rss_html import render_rss_html_content
            from pathlib import Path

            html_content = render_rss_html_content(
                rss_items=rss_items,
                total_count=len(rss_items),
                feeds_info=feeds_info,
                get_time_func=self.ctx.get_time,
            )

            # ä¿å­˜ HTML æ–‡ä»¶
            date_folder = self.ctx.format_date()
            time_filename = self.ctx.format_time()
            output_dir = Path("output") / date_folder / "html"
            output_dir.mkdir(parents=True, exist_ok=True)

            file_path = output_dir / f"rss_{time_filename}.html"
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(html_content)

            print(f"[RSS] HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {file_path}")
            return str(file_path)

        except Exception as e:
            print(f"[RSS] ç”Ÿæˆ HTML æŠ¥å‘Šå¤±è´¥: {e}")
            return None

    def _execute_mode_strategy(
        self, mode_strategy: Dict, results: Dict, id_to_name: Dict, failed_ids: List,
        rss_items: Optional[List[Dict]] = None,
        rss_new_items: Optional[List[Dict]] = None,
    ) -> Optional[str]:
        """æ‰§è¡Œæ¨¡å¼ç‰¹å®šé€»è¾‘ï¼Œæ”¯æŒçƒ­æ¦œ+RSSåˆå¹¶æ¨é€"""
        # è·å–å½“å‰ç›‘æ§å¹³å°IDåˆ—è¡¨
        current_platform_ids = self.ctx.platform_ids

        new_titles = self.ctx.detect_new_titles(current_platform_ids)
        time_info = self.ctx.format_time()
        if self.ctx.config["STORAGE"]["FORMATS"]["TXT"]:
            self.ctx.save_titles(results, id_to_name, failed_ids)
        word_groups, filter_words, global_filters = self.ctx.load_frequency_words()

        # currentæ¨¡å¼ä¸‹ï¼Œå®æ—¶æ¨é€éœ€è¦ä½¿ç”¨å®Œæ•´çš„å†å²æ•°æ®æ¥ä¿è¯ç»Ÿè®¡ä¿¡æ¯çš„å®Œæ•´æ€§
        if self.report_mode == "current":
            # åŠ è½½å®Œæ•´çš„å†å²æ•°æ®ï¼ˆå·²æŒ‰å½“å‰å¹³å°è¿‡æ»¤ï¼‰
            analysis_data = self._load_analysis_data()
            if analysis_data:
                (
                    all_results,
                    historical_id_to_name,
                    historical_title_info,
                    historical_new_titles,
                    _,
                    _,
                    _,
                ) = analysis_data

                print(
                    f"currentæ¨¡å¼ï¼šä½¿ç”¨è¿‡æ»¤åçš„å†å²æ•°æ®ï¼ŒåŒ…å«å¹³å°ï¼š{list(all_results.keys())}"
                )

                stats, html_file = self._run_analysis_pipeline(
                    all_results,
                    self.report_mode,
                    historical_title_info,
                    historical_new_titles,
                    word_groups,
                    filter_words,
                    historical_id_to_name,
                    failed_ids=failed_ids,
                    global_filters=global_filters,
                    rss_items=rss_items,
                    rss_new_items=rss_new_items,
                )

                combined_id_to_name = {**historical_id_to_name, **id_to_name}

                if html_file:
                    print(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}")

                # å‘é€å®æ—¶é€šçŸ¥ï¼ˆä½¿ç”¨å®Œæ•´å†å²æ•°æ®çš„ç»Ÿè®¡ç»“æœï¼Œåˆå¹¶RSS+AIæ€»ç»“ï¼‰
                summary_html = None
                if mode_strategy["should_send_realtime"]:
                    # ç”Ÿæˆ AI æ€»ç»“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    ai_summary = self._generate_ai_summary(rss_items=rss_items)
                    self._send_notification_if_needed(
                        stats,
                        mode_strategy["realtime_report_type"],
                        self.report_mode,
                        failed_ids=failed_ids,
                        new_titles=historical_new_titles,
                        id_to_name=combined_id_to_name,
                        html_file_path=html_file,
                        rss_items=rss_items,
                        rss_new_items=rss_new_items,
                        ai_summary=ai_summary,
                    )
            else:
                print("[ERROR] Cannot read data file after saving")
                raise RuntimeError("æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ï¼šä¿å­˜åç«‹å³è¯»å–å¤±è´¥")
        else:
            title_info = self._prepare_current_title_info(results, time_info)
            stats, html_file = self._run_analysis_pipeline(
                results,
                self.report_mode,
                title_info,
                new_titles,
                word_groups,
                filter_words,
                id_to_name,
                failed_ids=failed_ids,
                global_filters=global_filters,
                rss_items=rss_items,
                rss_new_items=rss_new_items,
            )
            if html_file:
                print(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_file}")

            # å‘é€å®æ—¶é€šçŸ¥ï¼ˆå¦‚æœéœ€è¦ï¼Œåˆå¹¶RSS+AIæ€»ç»“ï¼‰
            summary_html = None
            if mode_strategy["should_send_realtime"]:
                # ç”Ÿæˆ AI æ€»ç»“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                ai_summary = self._generate_ai_summary(rss_items=rss_items)
                self._send_notification_if_needed(
                    stats,
                    mode_strategy["realtime_report_type"],
                    self.report_mode,
                    failed_ids=failed_ids,
                    new_titles=new_titles,
                    id_to_name=id_to_name,
                    html_file_path=html_file,
                    rss_items=rss_items,
                    rss_new_items=rss_new_items,
                    ai_summary=ai_summary,
                )

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼ˆå¦‚æœéœ€è¦ï¼‰
        summary_html = None
        if mode_strategy["should_generate_summary"]:
            if mode_strategy["should_send_realtime"]:
                # å¦‚æœå·²ç»å‘é€äº†å®æ—¶é€šçŸ¥ï¼Œæ±‡æ€»åªç”ŸæˆHTMLä¸å‘é€é€šçŸ¥
                summary_html = self._generate_summary_html(
                    mode_strategy["summary_mode"],
                    rss_items=rss_items,
                    rss_new_items=rss_new_items,
                )
            else:
                # dailyæ¨¡å¼ï¼šç›´æ¥ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¹¶å‘é€é€šçŸ¥ï¼ˆåˆå¹¶RSSï¼‰
                summary_html = self._generate_summary_report(
                    mode_strategy, rss_items=rss_items, rss_new_items=rss_new_items
                )

        # æ‰“å¼€æµè§ˆå™¨ï¼ˆä»…åœ¨éå®¹å™¨ç¯å¢ƒï¼‰
        if self._should_open_browser() and html_file:
            if summary_html:
                summary_url = "file://" + str(Path(summary_html).resolve())
                print(f"æ­£åœ¨æ‰“å¼€æ±‡æ€»æŠ¥å‘Š: {summary_url}")
                webbrowser.open(summary_url)
            else:
                file_url = "file://" + str(Path(html_file).resolve())
                print(f"æ­£åœ¨æ‰“å¼€HTMLæŠ¥å‘Š: {file_url}")
                webbrowser.open(file_url)
        elif self.is_docker_container and html_file:
            if summary_html:
                print(f"æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆï¼ˆDockerç¯å¢ƒï¼‰: {summary_html}")
            else:
                print(f"HTMLæŠ¥å‘Šå·²ç”Ÿæˆï¼ˆDockerç¯å¢ƒï¼‰: {html_file}")

        return summary_html

    def run(self) -> None:
        """æ‰§è¡Œåˆ†ææµç¨‹"""
        try:
            self._initialize_and_check_config()

            mode_strategy = self._get_mode_strategy()

            # æŠ“å–çƒ­æ¦œæ•°æ®
            results, id_to_name, failed_ids = self._crawl_data()

            # æŠ“å– RSS æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰ï¼Œè¿”å›ç»Ÿè®¡æ¡ç›®å’Œæ–°å¢æ¡ç›®ç”¨äºåˆå¹¶æ¨é€
            rss_items, rss_new_items = self._crawl_rss_data()

            # æ‰§è¡Œæ¨¡å¼ç­–ç•¥ï¼Œä¼ é€’ RSS æ•°æ®ç”¨äºåˆå¹¶æ¨é€
            self._execute_mode_strategy(
                mode_strategy, results, id_to_name, failed_ids,
                rss_items=rss_items, rss_new_items=rss_new_items
            )

        except Exception as e:
            print(f"åˆ†ææµç¨‹æ‰§è¡Œå‡ºé”™: {e}")
            raise
        finally:
            # æ¸…ç†èµ„æºï¼ˆåŒ…æ‹¬è¿‡æœŸæ•°æ®æ¸…ç†å’Œæ•°æ®åº“è¿æ¥å…³é—­ï¼‰
            self.ctx.cleanup()


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    try:
        analyzer = NewsAnalyzer()
        analyzer.run()
    except FileNotFoundError as e:
        print(f"[ERROR] Config file error: {e}")
        print("\nè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
        print("  â€¢ config/config.yaml")
        print("  â€¢ config/frequency_words.txt")
        print("\nå‚è€ƒé¡¹ç›®æ–‡æ¡£è¿›è¡Œæ­£ç¡®é…ç½®")
    except Exception as e:
        print(f"[ERROR] Program error: {e}")
        raise


if __name__ == "__main__":
    main()
